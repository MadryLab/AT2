# AT2: Learning to Attribute with Attention

`at2` is a method for using attention to pinpoint the specific information that a language model *uses* when generating a particular statement.
This "information" can be, for example, a user-provided context, search results relevant to a query, or the models own intermediate thoughts.
When attributing a generated statement to context, the attributed sources can be interpreted as *citations* for the statement (see [ContextCite](https://github.com/MadryLab/context-cite)).

The attention mechanism 

## Getting started