{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train AT2\n",
    "\n",
    "In this notebook, we'll walk through training an AT2 score estimator.\n",
    "We'll consider the problem of context attribution (attributing a model's generation to in-context information).\n",
    "\n",
    "As a training dataset, we'll be using a subset of [`databricks-dolly-15k`](https://huggingface.co/datasets/databricks/databricks-dolly-15k), an instruction following dataset which includes summarization, context-based question answering, and information extraction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /mnt/xfs/home/bencw/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "from at2.utils import get_model_and_tokenizer\n",
    "from at2.tasks import SimpleContextAttributionTask\n",
    "from at2 import AT2Trainer, AT2Attributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading 1,000 random examples from the dataset, filtering to only include examples with a context and to omit examples with very long contexts (to make training easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(example):\n",
    "    valid_category = example[\"category\"] in [\"summarization\", \"closed_qa\", \"information_extraction\"]\n",
    "    valid_length = len(example[\"context\"]) < 20_000\n",
    "    return valid_category and valid_length\n",
    "\n",
    "raw_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "dataset = raw_dataset.filter(filter_fn).shuffle(seed=42).select(range(1_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'In this reference text summarizing plot of the book The High King, how did the sword Dyrnwyn lose its power?',\n",
       " 'context': 'The story begins only days after the conclusion of Taran Wanderer. With winter approaching, Taran and his companion Gurgi return from their wanderings to Caer Dallben after getting news from Kaw the crow that Princess Eilonwy has returned from the Isle of Mona. Indeed, they find her at home, along with her escort King Rhun of Mona and the former giant Glew, who had been magically restored to human size by a potion from Dallben.\\n\\nBefore Taran can propose to Eilonwy, the bard-king Fflewddur Fflam and his mount Llyan arrive with a gravely injured Gwydion, Prince of Don. Servants of Arawn had assaulted them and seized the magical black sword Dyrnwyn. Fflewddur also states that Taran was involved in the ambush, baffling everyone. With Achren\\'s help, the truth is determined: Arawn himself has come from Annuvin to the verge of Caer Dallben in the guise of Taran, in order to lure Gwydion into the ambush.\\n\\nBecause Dyrnwyn may be pivotal as a threat to Arawn, Dallben consults the oracular pig Hen Wen to determine how it may be regained. During the reading, the ash rods used to communicate shatter and the two thirds of Hen Wen\\'s answer are discouraging and vague. When Gwydion heals sufficiently, he sets out with Taran and others to meet with King Smoit. Gwydion insists that he alone should enter Annuvin to seek the sword, but Smoit\\'s Cantrev Cadiffor is on the way. The small party divides, as Rhun and Eilonwy intend to visit the ships of Mona en route.\\n\\nWhen Gwydion, Taran, and others reach Caer Cadarn, they are imprisoned by Magg, the treacherous former Chief Steward of Mona, who has entered service with Arawn and taken over the fortress. When Eilonwy approaches with the other party, she detects something amiss and they cautiously send Fflewddur Fflam to the fortress as a bard. After entertaining the soldiers for a night, he returns with the bad news. Then the companions encounter Gwystyl of the Fair Folk outside the stronghold, en route home after closing the waypost near Annuvin, personally bearing final observations to King Eiddileg about preparations for war by Arawn\\'s forces. With Gwystyl\\'s assistance and store of magical smokes, fires, and concealments, the companions break in and free the prisoners. The plan goes awry, however; King Smoit and his men are finally able to regain control only by Rhun\\'s intervention, which costs his life.\\n\\nLearning from Gwystyl of the activities in Annuvin, Gwydion turns from the quest for Dyrnwyn to planning for battle at Caer Dathyl. Gwystyl, Fflewddur, and Taran leave to gather support, respectively from the Fair Folk, the northern realms, and the Free Commots. Kaw, sent out by Taran to reconnoiter the enemy, is attacked by Gwythaints while spying near Annuvin, but manages to reach Medwyn, who asks all the creatures of air and land to oppose the forces of Arawn. Taran, Coll, Eilonwy, and Gurgi muster the Commots, who rally to their friendship with Taran, and sends them marching in groups to Caer Dathyl while the smiths and weavers rallied by Hevydd and Dwyvach work day and night to equip them.\\n\\nSoon after Taran and the last Commots reach Caer Dathyl, King Pryderi arrives from the western realms. In council he announces his new allegiance to Arawn, for the good of all, because \"Arawn will do what the Sons of Don have failed to do: Make an end of endless wars among the cantrevs, and bring peace where there was none before.\" He is rejected utterly but permitted to return unharmed to his army, and at the next day the battle begins. Although the Sons of Don and allies initially have the best of it, the Cauldron-Born arrive en masse before evening, overwhelming the allies and razing Caer Dathyl to the ground.\\n\\nWith High King Math killed, Gwydion is proclaimed the new High King. With the bulk of the Cauldron-Born deployed outside of Annuvin, Gwydion determines that the best chance is to attack while it is guarded by mortal men alone. He will lead the Sons of Don to waiting ships on the north coast and attack by sea, while Taran leads the Commots to delay the Cauldron-Born\\'s return march, as their power wanes with time and distance from Annuvin.\\n\\nTaran and his army are able to hold the tired Cauldron-Born warriors beyond arm\\'s length by brute force, and turn the march from a straight and easy route into the rugged hills, although Coll dies in battle. Thanks to a company of Fair Folk, and to the animals sent by Medwyn, they destroy most of the Huntsmen who accompany and lead the undead. At last the Cauldron-Born break free of the hills and return to the lowland route. Regaining strength as they near Annuvin, it would be futile for the exhausted allies to meet them head-on again, so inevitably they take the long, easy route to Arawn\\'s stronghold.\\n\\nTaran and the remainder of his army finally reach Annuvin by a combination of the direct route, a mountain path of Doli\\'s, and a secret pass over Mount Dragon shown to them by Achren. Taran sees that victory is nearly in Gwydion\\'s hands, but also that the Cauldron-Born are about to reach Annuvin. In his alarm, Taran nearly falls off Mount Dragon, but is saved by the now-grown Gwythaint he had rescued so many years ago (The Book of Three). In a desperate attempt to fight off a group of Cauldron-Born who have discovered him on the mountain, he rolls a rock at them, and discovers Dyrnwyn in the hollow the stone occupied. Wielding Dyrnwyn, Taran slays the undead warrior who approaches to slay him, and at that instant all of the Cauldron-Born die as one.\\n\\nTaran\\'s group enters the fray, and the battle continues through the halls of Annuvin. Taran is almost deceived by Arawn - who has taken the guise of Gwydion - into giving up the sword. After the chaotic defeat of Arawn\\'s forces, the companions gather before the Great Hall. Achren identifies Arawn in the form of a nearby serpent preparing to strike Taran and grabs him. He strikes her fatally, but Taran kills him with Dyrnwyn. With the death of Arawn, the stronghold of Annuvin bursts in flame and falls in ruins, destroying all of the magical implements inside; only Gurgi manages to save several scrolls containing knowledge of farming, smithing, and other crafts. The sword Dyrnwyn begins to fade, losing its magic.\\n\\nThe allies travel to Caer Dallben, where Gwydion tells them that in victory the Sons of Don, with all kinsmen and kinswomen, must return to the Summer Country. Indeed, all those who still have magic will depart, and the Fair Folk and Medwyn have closed their realms to outsiders. Dallben and Eilonwy must also go, and others who have served well, Taran among them, are given the chance to accompany them. Taran proposes to Eilonwy at last, and she accepts.\\n\\nThe Sons of Don plan to leave the next day. However, Taran becomes uncomfortable about his decision overnight. The witches Orddu, Orwen and Orgoch appear before him and reveal that they too are departing, and leave him with an unfinished tapestry depicting his life. He realizes there is much work to be done to rebuild Prydain, and he has made many promises; so he determines to remain behind. Eilonwy is able to willingly give up her magical nature in order to remain with him, and the two are married.\\n\\nDallben reveals that with this last quest, Taran has completed a path prophesied in the Book of Three whereby an orphan of \"no station in life\" would succeed the Sons of Don as High King. Dallben had traveled to seek such a one and try to hasten the day of Arawn\\'s defeat; on this journey, he found a baby, hidden in the trees beside a battlefield and without any token of parentage, and took it in under the name Taran. Taran receives many gifts, including The Book of Three itself, although its powers, like all magic in Prydain, have also faded away with Arawn\\'s demise, leaving it only as a mere chronicle of Taran\\'s life. With Eilonwy by his side, Taran accepts his new responsibility and is hailed by his friends and battle companions as the new High King.',\n",
       " 'response': 'When Taran killed Arawn with Dyrnwyn in the stronghold of Annuvin, all magical implements inside were destroyed - Dyrnwyn also lost its magic.',\n",
       " 'category': 'closed_qa'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the model.\n",
    "We'll be working with [`microsoft/Phi-4-mini-instruct`](https://huggingface.co/microsoft/Phi-4-mini-instruct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41613503f42c4df2ab03dfe14b088781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-4-mini-instruct\"\n",
    "model, tokenizer = get_model_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn to attribute, we'll need to define an \"attribution task.\"\n",
    "An attribution task consists of an input sequence, a generated sequence, a model/tokenizer and a set of sources to which we would like to attribute the generated sequence.\n",
    "In the case of context attribution, the input sequence is a context and query, the generated sequence is the model's response and the sources are pieces of the context, e.g., sentences.\n",
    "We've defined a class, `SimpleContextAttributionTask` to be able to quickly create such a task from an example in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_from_example(example, model, tokenizer, source_type=\"token\"):\n",
    "    return SimpleContextAttributionTask(\n",
    "        context=example[\"context\"],\n",
    "        query=example[\"instruction\"],\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        source_type=source_type,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a task to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Context ###\n",
      "The story begins only days after the conclusion of Taran Wanderer. With winter approaching, Taran and his companion Gurgi return from their wanderings to Caer Dallben after getting news from Kaw the crow that Princess Eilonwy has returned from the Isle of Mona. Indeed, they find her at home, along with her escort King Rhun of Mona and the former giant Glew, who had been magically restored to human size by a potion from Dallben.\n",
      "\n",
      "Before Taran can propose to Eilonwy, the bard-king Fflewddur Fflam ...\n",
      "\n",
      "### Instruction ###\n",
      "In this reference text summarizing plot of the book The High King, how did the sword Dyrnwyn lose its power?\n",
      "\n",
      "### Generated response ###\n",
      "In the reference text summarizing the plot of \"The High King,\" the sword Dyrnwyn loses its power after the defeat of Arawn. The text states that with the death of Arawn, the stronghold of Annuvin bursts into flame and falls in ruins, destroying all of the magical implements inside, including Dyrnwyn. As a result, Dyrnwyn begins to fade and loses its magic.\n"
     ]
    }
   ],
   "source": [
    "example = dataset[0]\n",
    "task = task_from_example(example, model, tokenizer, source_type=\"sentence\")\n",
    "print(\"### Context ###\")\n",
    "print(example[\"context\"][:500] + \"...\" if len(example[\"context\"]) > 500 else example[\"context\"])\n",
    "print()\n",
    "print(\"### Instruction ###\")\n",
    "print(example[\"instruction\"])\n",
    "print()\n",
    "# Generates a response and caches relevant information for attribution\n",
    "print(\"### Generated response ###\")\n",
    "print(task.generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sources: 58\n",
      "Source #0:\n",
      "The story begins only days after the conclusion of Taran Wanderer.\n",
      "\n",
      "Source #1:\n",
      "With winter approaching, Taran and his companion Gurgi return from their wanderings to Caer Dallben after getting news from Kaw the crow that Princess Eilonwy has returned from the Isle of Mona.\n",
      "\n",
      "Source #2:\n",
      "Indeed, they find her at home, along with her escort King Rhun of Mona and the former giant Glew, who had been magically restored to human size by a potion from Dallben.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sources:\", task.num_sources)\n",
    "# This is the first few sources (sentences from the context)\n",
    "for i in range(3):\n",
    "    print(f\"Source #{i}:\")\n",
    "    print(task.sources[i].strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train AT2 on our dataset!\n",
    "To do so, we'll first create an `AT2Trainer`.\n",
    "From there, training involves three steps:\n",
    "1. Generating a response for each task (from the context and query).\n",
    "1. Computing features (attention weights) and outputs (logit probabilities for a few ablations of the sources).\n",
    "1. Actually training a score estimator to predict the effects of ablations using the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"outputs\") / \"test_context_phi_4_mini_instruct\"\n",
    "\n",
    "trainer = AT2Trainer(\n",
    "    save_path=save_path,\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task_from_example=task_from_example,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cf50bdc7c149eeb4e1f6e3920ee754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating completions:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To parallelize across multiple jobs, set `num_jobs` and `job_index`\n",
    "trainer.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842bd4009ea9410191720cd158de84f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing features and outputs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To parallelize across multiple jobs, set `num_jobs` and `job_index`\n",
    "trainer.compute_features_and_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 994 examples of 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c1dcce7363493ea446d46533e63c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training score estimator:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss=-0.2556\n",
      "Step 99: loss=-0.5373\n",
      "Step 199: loss=-0.5693\n",
      "Step 299: loss=-0.5703\n",
      "Step 399: loss=-0.573\n",
      "Step 499: loss=-0.5747\n",
      "Step 599: loss=-0.5749\n",
      "Step 699: loss=-0.5781\n",
      "Step 799: loss=-0.5779\n",
      "Step 899: loss=-0.5781\n",
      "Step 999: loss=-0.5779\n",
      "Saved estimator to outputs/test_context_phi_4_mini_instruct/estimators/default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearScoreEstimator(\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A few examples without at least one valid sentence in the response are excluded\n",
    "trainer.train(save_name=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up, we'll use the score estimator we've just trained to attribute a response for a request to summarize an article from [CNN DailyMail](https://huggingface.co/datasets/abisee/cnn_dailymail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "example = dataset[0]\n",
    "\n",
    "task = SimpleContextAttributionTask(\n",
    "    context=example[\"article\"],\n",
    "    query=\"Summarize the article in up to three sentences.\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    source_type=\"sentence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[(0, 139)]\u001b[0mZully Broussard's selfless act of donating a kidney to a stranger led to a chain reaction, resulting in six patients receiving transplants. \u001b[36m[(140, 312)]\u001b[0mThe process, which took only three weeks, was made possible by a computer program called MatchGrid, created by David Jacobs, which quickly matches up donor pairs or chains. \u001b[36m[(313, 491)]\u001b[0mThe chain of surgeries, which involved five surgeons, a team of physician assistants, nurses, anesthesiologists, and more than 40 support staff, is set to be completed by Friday.\n"
     ]
    }
   ],
   "source": [
    "task.show_target_with_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing attribution scores for:\n",
      " The process, which took only three weeks, was made possible by a computer program called MatchGrid, created by David Jacobs, which quickly matches up donor pairs or chains.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ebac_row0_col0 {\n",
       "  background-color: #053061;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7ebac_row1_col0 {\n",
       "  background-color: #7bb6d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7ebac_row2_col0 {\n",
       "  background-color: #c2ddec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7ebac_row3_col0 {\n",
       "  background-color: #d2e6f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7ebac_row4_col0, #T_7ebac_row5_col0 {\n",
       "  background-color: #e7f0f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7ebac_row6_col0, #T_7ebac_row7_col0 {\n",
       "  background-color: #e9f0f4;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ebac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ebac_level0_col0\" class=\"col_heading level0 col0\" >Score</th>\n",
       "      <th id=\"T_7ebac_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7ebac_row0_col0\" class=\"data row0 col0\" >0.004</td>\n",
       "      <td id=\"T_7ebac_row0_col1\" class=\"data row0 col1\" > Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7ebac_row1_col0\" class=\"data row1 col0\" >0.002</td>\n",
       "      <td id=\"T_7ebac_row1_col1\" class=\"data row1 col1\" > That changed when a computer programmer named David Jacobs received a kidney transplant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7ebac_row2_col0\" class=\"data row2 col0\" >0.001</td>\n",
       "      <td id=\"T_7ebac_row2_col1\" class=\"data row2 col1\" > We did this in about three weeks,\" Jacobs said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7ebac_row3_col0\" class=\"data row3 col0\" >0.001</td>\n",
       "      <td id=\"T_7ebac_row3_col1\" class=\"data row3 col1\" > But the power that multiplied Broussard's gift was data processing of genetic profiles from donor-recipient pairs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7ebac_row4_col0\" class=\"data row4 col0\" >0.000</td>\n",
       "      <td id=\"T_7ebac_row4_col1\" class=\"data row4 col1\" > It's been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7ebac_row5_col0\" class=\"data row5 col0\" >0.000</td>\n",
       "      <td id=\"T_7ebac_row5_col1\" class=\"data row5 col1\" > It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7ebac_row6_col0\" class=\"data row6 col0\" >0.000</td>\n",
       "      <td id=\"T_7ebac_row6_col1\" class=\"data row6 col1\" > \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ebac_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7ebac_row7_col0\" class=\"data row7 col0\" >0.000</td>\n",
       "      <td id=\"T_7ebac_row7_col1\" class=\"data row7 col1\" > So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff01148ff10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributor = AT2Attributor.from_path(\n",
    "    task, trainer.save_path / \"estimators\" / \"default\" / \"score_estimator.pt\"\n",
    ")\n",
    "start, end = (140, 312)\n",
    "attributor.show_attribution(start=start, end=end, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
